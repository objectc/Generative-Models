{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/objectc/Generative-Models/blob/master/CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkX-XPPgZwha",
        "colab_type": "code",
        "outputId": "af084138-9068-46a6-c070-c7edb746633b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 16kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.16.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0a20190603)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.11.1)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (0.15.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.0.0b1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1yv1KPhAnhV",
        "colab_type": "text"
      },
      "source": [
        "Install keras-contrib for InstanceNormalization, you can also implement it by yourself. See [this link](https://stackoverflow.com/a/48118940/1651560) for the details of InstanceNormalization and BatchNormalization.\n",
        "P.S I forked the original repo and updated the code in order to make it compatible with TensorFlow 2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uhdn3A2AsWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7b3d119c-9f31-4fdd-d508-086d867b1053"
      },
      "source": [
        "!pip --upgrade --force-reinstall install git+https://github.com/objectc/keras-contrib.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "no such option: --upgrade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4gr-VieC3Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d082e76-80b3-4524-e4e1-e91fd97a8cc6"
      },
      "source": [
        "!pip install --force-reinstall git+https://github.com/objectc/keras-contrib.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/objectc/keras-contrib.git\n",
            "  Cloning https://github.com/objectc/keras-contrib.git to /tmp/pip-req-build-rpbtvuvi\n",
            "  Running command git clone -q https://github.com/objectc/keras-contrib.git /tmp/pip-req-build-rpbtvuvi\n",
            "Collecting keras (from keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.0MB/s \n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 27.4MB/s \n",
            "\u001b[?25hCollecting scipy>=0.14 (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 60.2MB/s \n",
            "\u001b[?25hCollecting six>=1.9.0 (from keras->keras-contrib==2.0.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting numpy>=1.9.1 (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 42.4MB/s \n",
            "\u001b[?25hCollecting h5py (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 56.2MB/s \n",
            "\u001b[?25hCollecting pyyaml (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 52.9MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6 (from keras->keras-contrib==2.0.8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 25.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: keras-contrib, pyyaml\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xm_ac9ws/wheels/d2/2a/6c/779d9d2e162e445e3eba9b4402cfb9380dc997f5f150a808b8\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built keras-contrib pyyaml\n",
            "\u001b[31mERROR: jupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.16 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, six, keras-preprocessing, scipy, h5py, pyyaml, keras-applications, keras, keras-contrib\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: Keras-Preprocessing 1.1.0\n",
            "    Uninstalling Keras-Preprocessing-1.1.0:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
            "  Found existing installation: scipy 1.3.0\n",
            "    Uninstalling scipy-1.3.0:\n",
            "      Successfully uninstalled scipy-1.3.0\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Keras-Applications 1.0.8\n",
            "    Uninstalling Keras-Applications-1.0.8:\n",
            "      Successfully uninstalled Keras-Applications-1.0.8\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Found existing installation: keras-contrib 2.0.8\n",
            "    Uninstalling keras-contrib-2.0.8:\n",
            "      Successfully uninstalled keras-contrib-2.0.8\n",
            "Successfully installed h5py-2.9.0 keras-2.2.4 keras-applications-1.0.8 keras-contrib-2.0.8 keras-preprocessing-1.1.0 numpy-1.16.4 pyyaml-5.1.1 scipy-1.3.0 six-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "keras_applications",
                  "keras_preprocessing",
                  "numpy",
                  "scipy",
                  "six",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkx9aivBxfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43818524-4748-4542-ac42-ae136c54fd4e"
      },
      "source": [
        "!ls /usr/local/lib/python3.6/dist-packages/keras_contrib/layers/normalization/"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access '/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/normalization/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS0HM_lXKORq",
        "colab_type": "text"
      },
      "source": [
        "This implementation of CycleGAN are based on the paper [Unpaired Image-to-Image Translation\n",
        "using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANWbxAZoaDL8",
        "colab_type": "code",
        "outputId": "06c9644d-ae79-4750-f363-6df7c874423c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate, BatchNormalization, Activation, ZeroPadding2D, LeakyReLU, UpSampling2D, Conv2D\n",
        "from keras_contrib.layers import InstanceNormalization\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import functools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upb3q-HsvepX",
        "colab_type": "text"
      },
      "source": [
        "According to the paper,  reflection padding was used to reduce artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0FGAoEvvcbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Keras does not provide reflection padding implementation, we need to custom our own padding layer class.\n",
        "\n",
        "class ReflectionPadding2D(keras.layers.Layer):\n",
        "    def __init__(self, kernel_size = None, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        # if kernel_size pass in, use half of it as the padding\n",
        "        if kernel_size:\n",
        "          self.padding = (kernel_size//2, kernel_size//2)\n",
        "        self.input_spec = [keras.layers.InputSpec(ndim=4)]\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, s):\n",
        "        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n",
        "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        w_pad,h_pad = self.padding\n",
        "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFdyXjR8aUrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CycleGAN:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.input_shape = (128, 128, 3)\n",
        "    self.conv = functools.partial(keras.layers.Conv2D, kernel_size=3, strides=2, activation=LeakyReLU, padding='same')\n",
        "  \n",
        "  # Residual blocks\n",
        "  def residual(self, X, filters):\n",
        "    X_shortcut = X\n",
        "#     output = InstanceNormalization()(X)\n",
        "#     output = keras.layers.LeakyReLU()(output)\n",
        "    output = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(X)\n",
        "\n",
        "    output = InstanceNormalization()(output)\n",
        "    output = keras.layers.LeakyReLU()(output)\n",
        "    output = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=\"same\")(output)\n",
        "\n",
        "    output = keras.layers.add([X_shortcut,output])\n",
        "\n",
        "    return output\n",
        "  \n",
        "  def create_generator(self):\n",
        "    def conv(layer_input, filters, kernel_size=3, strides=2):\n",
        "      output = ReflectionPadding2D(kernel_size=kernel_size)\n",
        "      output = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides)(layer_input)\n",
        "      # The paper point out that they use InstanceNormalization instead of BatchNormalization. \n",
        "      output = InstanceNormalization()(output)\n",
        "      output = keras.layers.LeakyReLU()(output)\n",
        "      return output\n",
        "      \n",
        "    input = keras.layers.Input(shape=self.input_shape)\n",
        "    # Downsampling\n",
        "    d = conv(input, filters=64, kernel_size=7, strides=1)\n",
        "    d = conv(d, filters=128, kernel_size=3, strides=2)\n",
        "    d = conv(d, filters=256, kernel_size=3, strides=2)\n",
        "    \n",
        "    # resnet layers\n",
        "    for i in range(6):\n",
        "      r = self.residual(d, 256)\n",
        "      \n",
        "    # Upsampling\n",
        "    u = InstanceNormalization()(r)\n",
        "    u = keras.layers.LeakyReLU()(u)\n",
        "    u = keras.layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(u)\n",
        "    u = InstanceNormalization()(u)\n",
        "    u = keras.layers.LeakyReLU()(u)\n",
        "    u = keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(u)\n",
        "    u = InstanceNormalization()(u)\n",
        "    u = keras.layers.LeakyReLU()(u)\n",
        "    output = keras.layers.Conv2DTranspose(3, kernel_size=7, padding='same', activation='tanh')(u)\n",
        "    return keras.models.Model(input, output)\n",
        "    \n",
        "\n",
        "  \n",
        "  def create_discriminator(self):\n",
        "    input = Input(shape=self.input_shape)\n",
        "    d = input\n",
        "    kernel_size = 4\n",
        "    for depth in range(4):\n",
        "      if depth == 3:\n",
        "        d = keras.layers.ZeroPadding2D(1)(d)\n",
        "      d = keras.layers.Conv2D(64*(2**depth), kernel_size=kernel_size, strides=2, padding='same')(d)\n",
        "      if depth > 0:\n",
        "        d = InstanceNormalization()(d)\n",
        "      d = keras.layers.LeakyReLU()(d)\n",
        "    output = keras.layers.ZeroPadding2D(1)(d)\n",
        "    output = keras.layers.Conv2D(1, kernel_size=kernel_size, activation='sigmoid')(output)\n",
        "    return Model(input, output)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoDVAZhM91Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN = CycleGAN()\n",
        "gen = GAN.create_generator()\n",
        "dis = GAN.create_discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1-2qcKuwNiy",
        "colab_type": "text"
      },
      "source": [
        "The [PatchGAN](https://arxiv.org/pdf/1611.07004.pdf) / Markovian discriminator works by classifying individual (N x N) patches in the image as “real vs. fake”, opposed to classifying the entire image as “real vs. fake”. The authors reason that this enforces more constraints that encourage sharp high-frequency detail. Additionally, the PatchGAN has fewer parameters and runs faster than classifying the entire image.\n",
        "Read for more details [here](https://towardsdatascience.com/pix2pix-869c17900998)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMWYKg6QbcYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Images size\n",
        "w = 256\n",
        "h = 256\n",
        "\n",
        "# Cyclic consistency factor\n",
        "\n",
        "lmda = 10\n",
        "\n",
        "# Optimizer parameters\n",
        "\n",
        "lr = 0.0002\n",
        "beta_1 = 0.5\n",
        "beta_2 = 0.999\n",
        "epsilon = 1e-08\n",
        "\n",
        "\n",
        "\n",
        "disc_a_history = []\n",
        "disc_b_history = []\n",
        "\n",
        "gen_a2b_history = {'bc':[], 'mae':[]} \n",
        "gen_b2a_history = {'bc':[], 'mae':[]}\n",
        "\n",
        "gen_b2a_history_new = []\n",
        "gen_a2b_history_new = []\n",
        "cycle_history = []\n",
        "\n",
        "# Data loading\n",
        "\n",
        "def loadImage(path, h, w):\n",
        "    \n",
        "    '''Load single image from specified path'''\n",
        "    img = image.load_img(path)\n",
        "    img = img.resize((w,h))\n",
        "    x = image.img_to_array(img)\n",
        "    return x\n",
        "\n",
        "\n",
        "def loadImagesFromDataset(h, w, dataset, use_hdf5=False):\n",
        "\n",
        "    '''Return a tuple (trainA, trainB, testA, testB) \n",
        "    containing numpy arrays populated from the\n",
        "     test and train set for each part of the cGAN'''\n",
        "\n",
        "    if (use_hdf5):\n",
        "        path=\"./datasets/processed/\"+dataset+\"_data.h5\"\n",
        "        data = []\n",
        "        print('\\n', '-' * 15, 'Loading data from dataset', dataset, '-' * 15)\n",
        "        with h5py.File(path, \"r\") as hf:\n",
        "            for set_name in tqdm([\"trainA_data\", \"trainB_data\", \"testA_data\", \"testB_data\"]):\n",
        "                data.append(hf[set_name][:].astype(np.float32))\n",
        "\n",
        "        return (set_data for set_data in data)\n",
        "\n",
        "    else:\n",
        "        path = \"./datasets/\"+dataset\n",
        "        print(path)\n",
        "        train_a = glob.glob(path + \"/trainA/*.png\")\n",
        "        train_b = glob.glob(path + \"/trainB/*.png\")\n",
        "        test_a = glob.glob(path + \"/testA/*.png\")\n",
        "        test_b = glob.glob(path + \"/testB/*.png\")\n",
        "\n",
        "        print(\"Import trainA\")\n",
        "        if dataset == \"nike2adidas\" or (\"adiedges\" in dataset):\n",
        "            tr_a = np.array([loadImage(p, h, w) for p in tqdm(train_a[:1000])])\n",
        "        else:\n",
        "            tr_a = np.array([loadImage(p, h, w) for p in tqdm(train_a)])\n",
        "\n",
        "        print(\"Import trainB\")\n",
        "        if dataset == \"nike2adidas\" or (\"adiedges\" in dataset):\n",
        "            tr_b = np.array([loadImage(p, h, w) for p in tqdm(train_b[:1000])])\n",
        "        else:\n",
        "            tr_b = np.array([loadImage(p, h, w) for p in tqdm(train_b)])\n",
        "\n",
        "        print(\"Import testA\")\n",
        "        ts_a = np.array([loadImage(p, h, w) for p in tqdm(test_a)])\n",
        "\n",
        "        print(\"Import testB\")\n",
        "        ts_b = np.array([loadImage(p, h, w) for p in tqdm(test_b)])\n",
        "\n",
        "    return tr_a, tr_b, ts_a, ts_b\n",
        "    \n",
        "\n",
        "\n",
        "# Create a wall of generated images\n",
        "\n",
        "def plotGeneratedImages(epoch, set_a, set_b, generator_a2b, generator_b2a, examples=6):\n",
        "    \n",
        "    true_batch_a = set_a[np.random.randint(0, set_a.shape[0], size=examples)]\n",
        "    true_batch_b = set_b[np.random.randint(0, set_b.shape[0], size=examples)]\n",
        "\n",
        "    # Get fake and cyclic images\n",
        "    generated_a2b = generator_a2b.predict(true_batch_a)\n",
        "    cycle_a = generator_b2a.predict(generated_a2b)\n",
        "    generated_b2a = generator_b2a.predict(true_batch_b)\n",
        "    cycle_b = generator_a2b.predict(generated_b2a)\n",
        "    \n",
        "    k = 0\n",
        "\n",
        "    # Allocate figure\n",
        "    plt.figure(figsize=(w/10, h/10))\n",
        "\n",
        "    for output in [true_batch_a, generated_a2b, cycle_a, true_batch_b, generated_b2a, cycle_b]:\n",
        "        output = (output+1.0)/2.0\n",
        "        for i in range(output.shape[0]):\n",
        "            plt.subplot(examples, examples, k*examples +(i + 1))\n",
        "            img = output[i].transpose(1, 2, 0)  # Using (ch, h, w) scheme needs rearranging for plt to (h, w, ch)\n",
        "            #print(img.shape)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        k += 1\n",
        "    plt.savefig(\"images/epoch\"+str(epoch)+\".png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Plot the loss from each batch\n",
        "\n",
        "def plotLoss_new():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(disc_a_history, label='Discriminator A loss')\n",
        "    plt.plot(disc_b_history, label='Discriminator B loss')\n",
        "    plt.plot(gen_a2b_history_new, label='Generator a2b loss')\n",
        "    plt.plot(gen_b2a_history_new, label='Generator b2a loss')\n",
        "    #plt.plot(cycle_history, label=\"Cyclic loss\")\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('images/cyclegan_loss.png')\n",
        "    plt.close()\n",
        "\n",
        "def saveModels(epoch, genA2B, genB2A, discA, discB):\n",
        "    genA2B.save('models/generatorA2B_epoch_%d.h5' % epoch)\n",
        "    genB2A.save('models/generatorB2A_epoch_%d.h5' % epoch)\n",
        "    discA.save('models/discriminatorA_epoch_%d.h5' % epoch)\n",
        "    discB.save('models/discriminatorB_epoch_%d.h5' % epoch)\n",
        "\n",
        "\n",
        "# Training\n",
        "\n",
        "def train(epochs, batch_size, dataset, baselr, use_pseudounet=False, use_unet=False, use_decay=False, plot_models=True):\n",
        "\n",
        "    # Load data and normalize\n",
        "    x_train_a, x_train_b, x_test_a, x_test_b = loadImagesFromDataset(h, w, dataset, use_hdf5=False)\n",
        "\n",
        "    x_train_a = (x_train_a.astype(np.float32) - 127.5) / 127.5\n",
        "    x_train_b = (x_train_b.astype(np.float32) - 127.5) / 127.5\n",
        "    x_test_a = (x_test_a.astype(np.float32) - 127.5) / 127.5\n",
        "    x_test_b = (x_test_b.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    batchCount_a = x_train_a.shape[0] / batch_size\n",
        "    batchCount_b = x_train_b.shape[0] / batch_size\n",
        "\n",
        "    # Train on same image amount, would be best to have even sets\n",
        "    batchCount = min([batchCount_a, batchCount_b])\n",
        "\n",
        "    print('\\nEpochs:', epochs)\n",
        "    print('Batch size:', batch_size)\n",
        "    print('Batches per epoch: ', batchCount, \"\\n\")\n",
        "\n",
        "    #Retrieve components and save model before training, to preserve weights initialization\n",
        "    disc_a, disc_b, gen_a2b, gen_b2a = components(w, h, pseudounet=use_pseudounet, unet=use_unet, plot=plot_models)\n",
        "    saveModels(0, gen_a2b, gen_b2a, disc_a, disc_b)\n",
        "\n",
        "    #Initialize fake images pools\n",
        "    pool_a2b = []\n",
        "    pool_b2a = []\n",
        "\n",
        "    # Define optimizers\n",
        "    adam_disc = Adam(lr=baselr, beta_1=0.5)\n",
        "    adam_gen = Adam(lr=baselr, beta_1=0.5)\n",
        "\n",
        "    # Define image batches\n",
        "    true_a = gen_a2b.inputs[0]\n",
        "    true_b = gen_b2a.inputs[0]\n",
        "\n",
        "    fake_b = gen_a2b.outputs[0]\n",
        "    fake_a = gen_b2a.outputs[0]\n",
        "\n",
        "    fake_pool_a = K.placeholder(shape=(None, 3, h, w))\n",
        "    fake_pool_b = K.placeholder(shape=(None, 3, h, w))\n",
        "\n",
        "    # Labels for generator training\n",
        "    y_fake_a = K.ones_like(disc_a([fake_a]))\n",
        "    y_fake_b = K.ones_like(disc_b([fake_b]))\n",
        "\n",
        "    # Labels for discriminator training\n",
        "    y_true_a = K.ones_like(disc_a([true_a])) * 0.9\n",
        "    y_true_b = K.ones_like(disc_b([true_b])) * 0.9\n",
        "\n",
        "    fakelabel_a2b = K.zeros_like(disc_b([fake_b]))\n",
        "    fakelabel_b2a = K.zeros_like(disc_a([fake_a]))\n",
        "\n",
        "    # Define losses\n",
        "    disc_a_loss = mse_loss(y_true_a, disc_a([true_a])) + mse_loss(fakelabel_b2a, disc_a([fake_pool_a]))\n",
        "    disc_b_loss = mse_loss(y_true_b, disc_b([true_b])) + mse_loss(fakelabel_a2b, disc_b([fake_pool_b]))\n",
        "\n",
        "    gen_a2b_loss = mse_loss(y_fake_b, disc_b([fake_b]))\n",
        "    gen_b2a_loss = mse_loss(y_fake_a, disc_a([fake_a]))\n",
        "\n",
        "    cycle_a_loss = mae_loss(true_a, gen_b2a([fake_b]))\n",
        "    cycle_b_loss = mae_loss(true_b, gen_a2b([fake_a]))\n",
        "    cyclic_loss = cycle_a_loss + cycle_b_loss\n",
        "\n",
        "    # Prepare discriminator updater\n",
        "    discriminator_weights = disc_a.trainable_weights + disc_b.trainable_weights\n",
        "    disc_loss = (disc_a_loss + disc_b_loss) * 0.5\n",
        "    discriminator_updater = adam_disc.get_updates(discriminator_weights, [], disc_loss)\n",
        "\n",
        "    # Prepare generator updater\n",
        "    generator_weights = gen_a2b.trainable_weights + gen_b2a.trainable_weights\n",
        "    gen_loss = (gen_a2b_loss + gen_b2a_loss + lmda * cyclic_loss)\n",
        "    generator_updater = adam_gen.get_updates(generator_weights, [], gen_loss)\n",
        "\n",
        "    # Define trainers\n",
        "    generator_trainer = K.function([true_a, true_b], [gen_a2b_loss, gen_b2a_loss, cyclic_loss], generator_updater)\n",
        "    discriminator_trainer = K.function([true_a, true_b, fake_pool_a, fake_pool_b], [disc_a_loss/2, disc_b_loss/2], discriminator_updater)\n",
        "\n",
        "    epoch_counter = 1\n",
        "\n",
        "    # Start training\n",
        "    for e in range(1, epochs + 1):\n",
        "        print('\\n','-'*15, 'Epoch %d' % e, '-'*15)\n",
        "\n",
        "        #Learning rate decay\n",
        "        if use_decay and (epoch_counter > 100):\n",
        "            lr -= baselr/100\n",
        "            adam_disc.lr = lr\n",
        "            adam_gen.lr = lr\n",
        "\n",
        "\n",
        "        # Initialize progbar and batch counter\n",
        "        #progbar = generic_utils.Progbar(batchCount)\n",
        "\n",
        "        np.random.shuffle(x_train_a)\n",
        "        np.random.shuffle(x_train_b)\n",
        "\n",
        "        # Cycle through batches\n",
        "        for i in trange(int(batchCount)):\n",
        "\n",
        "            # Select true images for training\n",
        "            #true_batch_a = x_train_a[np.random.randint(0, x_train_a.shape[0], size=batch_size)]\n",
        "            #true_batch_b = x_train_b[np.random.randint(0, x_train_b.shape[0], size=batch_size)]\n",
        "\n",
        "            true_batch_a = x_train_a[i*batch_size:i*batch_size+batch_size]\n",
        "            true_batch_b = x_train_b[i*batch_size:i*batch_size+batch_size]\n",
        "\n",
        "            # Fake images pool \n",
        "            a2b = gen_a2b.predict(true_batch_a)\n",
        "            b2a = gen_b2a.predict(true_batch_b)\n",
        "\n",
        "            tmp_b2a = []\n",
        "            tmp_a2b = []\n",
        "\n",
        "            for element in a2b:\n",
        "                if len(pool_a2b) < 50:\n",
        "                    pool_a2b.append(element)\n",
        "                    tmp_a2b.append(element)\n",
        "                else:\n",
        "                    p = random.uniform(0, 1)\n",
        "\n",
        "                    if p > 0.5:\n",
        "                        index = random.randint(0, 49)\n",
        "                        tmp = np.copy(pool_a2b[index])\n",
        "                        pool_a2b[index] = element\n",
        "                        tmp_a2b.append(tmp)\n",
        "                    else:\n",
        "                        tmp_a2b.append(element)\n",
        "            \n",
        "            for element in b2a:\n",
        "                if len(pool_b2a) < 50:\n",
        "                    pool_b2a.append(element)\n",
        "                    tmp_b2a.append(element)\n",
        "                else:\n",
        "                    p = random.uniform(0, 1)\n",
        "\n",
        "                    if p >0.5:\n",
        "                        index = random.randint(0, 49)\n",
        "                        tmp = np.copy(pool_b2a[index])\n",
        "                        pool_b2a[index] = element\n",
        "                        tmp_b2a.append(tmp)\n",
        "                    else:\n",
        "                        tmp_b2a.append(element)\n",
        "\n",
        "            pool_a = np.array(tmp_b2a)\n",
        "            pool_b = np.array(tmp_a2b)\n",
        "\n",
        "            # Update network and obtain losses\n",
        "            disc_a_err, disc_b_err = discriminator_trainer([true_batch_a, true_batch_b, pool_a, pool_b])\n",
        "            gen_a2b_err, gen_b2a_err, cyclic_err = generator_trainer([true_batch_a, true_batch_b])\n",
        "\n",
        "            # progbar.add(1, values=[\n",
        "            #                             (\"D A\", disc_a_err*2),\n",
        "            #                             (\"D B\", disc_b_err*2),\n",
        "            #                             (\"G A2B loss\", gen_a2b_err),\n",
        "            #                             (\"G B2A loss\", gen_b2a_err),\n",
        "            #                             (\"Cyclic loss\", cyclic_err)\n",
        "            #                            ])\n",
        "\n",
        "        # Save losses for plotting\n",
        "        disc_a_history.append(disc_a_err)\n",
        "        disc_b_history.append(disc_b_err)\n",
        "\n",
        "        gen_a2b_history_new.append(gen_a2b_err)\n",
        "        gen_b2a_history_new.append(gen_b2a_err)\n",
        "\n",
        "        #cycle_history.append(cyclic_err[0])\n",
        "        plotLoss_new()\n",
        "\n",
        "        plotGeneratedImages(epoch_counter, x_test_a, x_test_b, gen_a2b, gen_b2a)\n",
        "\n",
        "        if epoch_counter > 150:\n",
        "            saveModels(epoch_counter, gen_a2b, gen_b2a, disc_a, disc_b)\n",
        "\n",
        "        epoch_counter += 1\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train(200, 1, \"horse2zebra\", lr, use_decay=True, use_pseudounet=False, use_unet=False, plot_models=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}